import csv
import glob
import os

def find_all_logs(base_search_path: str) -> dict:
    """
    Scans a directory structure for all .log files and maps their
    base names to their full paths for quick lookup.

    Args:
        base_search_path: The root directory to start the search from (e.g., 'Z:/Bianca').

    Returns:
        A dictionary mapping a log's base name to its full file path.
    """
    # Construct the full glob pattern to search for .log files
    # This will match paths like 'Z:/Bianca/2025-08-14/01/some_file.log'
    glob_pattern = os.path.join(base_search_path, "????-??-??", "??", "*.log")
    
    print(f"Searching for log files using pattern: {glob_pattern}")
    
    # Find all files matching the pattern
    found_files = glob.glob(glob_pattern)
    
    log_map = {}
    for file_path in found_files:
        # Get the filename without the extension (the base name)
        base_name = os.path.splitext(os.path.basename(file_path))[0]
        # Map the base name to its full path for fast lookups
        log_map[base_name] = file_path
        
    print(f"Found {len(log_map)} unique .log files.")
    return log_map

def main():
    """
    Main function. Reads a CSV of filtered .txt files, finds their
    corresponding .log files in a specified directory structure,
    and writes the mapping to a new CSV.
    """
    # Input CSV generated by the 'error_code_parser_v1' script
    input_csv_path = 'core_error_140_analysis.csv'
    # The new CSV file this script will generate
    output_csv_path = 'found_log_file_locations.csv'
    # The base directory to search for the .log files
    log_search_directory = 'Z:/Bianca'

    # 1. Check if the input CSV from the previous step exists
    if not os.path.exists(input_csv_path):
        print(f"Error: Input file '{input_csv_path}' not found.")
        print("Please run the 'error_code_parser_v1' script first to generate it.")
        return

    # 2. Find all available .log files in the target directory and map them
    available_logs = find_all_logs(log_search_directory)
    
    if not available_logs:
        print(f"Warning: No .log files were found in the search path: {log_search_directory}")

    # 3. Read the input CSV and find matches
    results_to_write = []
    try:
        with open(input_csv_path, 'r', newline='', encoding='utf-8') as infile:
            reader = csv.DictReader(infile)
            for row in reader:
                original_txt_path = row.get('Filepath')
                if not original_txt_path:
                    continue

                # Get the base name of the .txt file, e.g., "file" from "path/to/file.txt"
                txt_base_name = os.path.splitext(os.path.basename(original_txt_path))[0]

                # Look for the corresponding .log file in our map
                found_log_path = available_logs.get(txt_base_name, "Not Found")
                
                if found_log_path != "Not Found":
                    print(f"Match found for '{txt_base_name}': {found_log_path}")
                else:
                    print(f"No match found for '{txt_base_name}'")
                
                results_to_write.append({
                    'Original_Txt_Filepath': original_txt_path,
                    'Corresponding_Log_Filepath': found_log_path
                })
        
        # 4. Write the results to the new CSV file
        if not results_to_write:
            print("No filepaths were processed from the input CSV.")
            return

        with open(output_csv_path, 'w', newline='', encoding='utf-8') as outfile:
            header = ['Original_Txt_Filepath', 'Corresponding_Log_Filepath']
            writer = csv.DictWriter(outfile, fieldnames=header)
            writer.writeheader()
            writer.writerows(results_to_write)

        print(f"\nSearch complete. Results written to '{output_csv_path}'.")

    except Exception as e:
        print(f"An unexpected error occurred: {e}")

if __name__ == "__main__":
    main()