import csv
import glob
import os

def main():
    """
    Main function. Reads a CSV of filtered .txt files, finds their
    corresponding .log files in a specified directory structure by using the
    path information from the CSV, and writes the mapping to a new CSV.
    """
    # Input CSV generated by the 'error_code_parser_v1' script
    input_csv_path = 'core_error_140_analysis.csv'
    # The new CSV file this script will generate
    output_csv_path = 'found_log_file_locations.csv'
    # The root directory to search for the .log files
    log_search_root = 'Z:/'

    # 1. Check if the input CSV from the previous step exists
    if not os.path.exists(input_csv_path):
        print(f"Error: Input file '{input_csv_path}' not found.")
        print("Please run the 'error_code_parser_v1' script first to generate it.")
        return

    # 2. Read the input CSV and find matches for each row
    results_to_write = []
    try:
        with open(input_csv_path, 'r', newline='', encoding='utf-8') as infile:
            reader = csv.DictReader(infile)
            print("Processing rows from input CSV...")
            
            for row in reader:
                original_txt_path = row.get('Filepath')
                if not original_txt_path:
                    continue

                # Get the directory and base name from the original .txt path
                # e.g., '2025-08-06' and 'some_file' from '2025-08-06/some_file.txt'
                txt_dir = os.path.dirname(original_txt_path)
                txt_base_name = os.path.splitext(os.path.basename(original_txt_path))[0]

                # Construct a specific search pattern for the corresponding .log file
                # This will look for a path like 'Z:/Bianca/2025-08-06/??/some_file.log'
                search_pattern = os.path.join(log_search_root, "Bianca", txt_dir, "??", f"{txt_base_name}.log")
                
                print(f"- Searching for: {search_pattern}")

                # Execute the search for the specific file
                found_files = glob.glob(search_pattern)
                
                found_log_path = "Not Found"
                if found_files:
                    # If found, take the first match
                    found_log_path = found_files[0]
                    print(f"  Match found: {found_log_path}")
                else:
                    print(f"  No match found.")
                
                results_to_write.append({
                    'Original_Txt_Filepath': original_txt_path,
                    'Corresponding_Log_Filepath': found_log_path
                })
        
        # 3. Write the results to the new CSV file
        if not results_to_write:
            print("No filepaths were processed from the input CSV.")
            return

        with open(output_csv_path, 'w', newline='', encoding='utf-8') as outfile:
            header = ['Original_Txt_Filepath', 'Corresponding_Log_Filepath']
            writer = csv.DictWriter(outfile, fieldnames=header)
            writer.writeheader()
            writer.writerows(results_to_write)

        print(f"\nSearch complete. Results written to '{output_csv_path}'.")

    except Exception as e:
        print(f"An unexpected error occurred: {e}")

if __name__ == "__main__":
    main()

    