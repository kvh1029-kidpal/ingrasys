import csv
import glob
import os

def find_all_logs(search_patterns: list[str]) -> dict:
    """
    Scans given directory structures for all .log files and maps their
    base names to their full paths for quick lookup.

    Args:
        search_patterns: A list of glob patterns to search for log files.

    Returns:
        A dictionary mapping a log's base name to its full file path.
    """
    all_found_files = []
    print("Searching for log files using the following patterns:")
    for pattern in search_patterns:
        print(f"- {pattern}")
        # Find all files matching the current pattern and add them to the master list
        all_found_files.extend(glob.glob(pattern))
    
    log_map = {}
    for file_path in all_found_files:
        # Get the filename without the extension (the base name)
        base_name = os.path.splitext(os.path.basename(file_path))[0]
        # Map the base name to its full path for fast lookups
        log_map[base_name] = file_path
        
    print(f"\nFound {len(log_map)} unique .log files across all specified paths.")
    return log_map

def main():
    """
    Main function. Reads a CSV of filtered .txt files, finds their
    corresponding .log files in a specified directory structure,
    and writes the mapping to a new CSV.
    """
    # Input CSV generated by the 'error_code_parser_v1' script
    input_csv_path = 'core_error_140_analysis.csv'
    # The new CSV file this script will generate
    output_csv_path = 'found_log_file_locations.csv'
    # The root directory to search for the .log files
    log_search_root = 'Z:/Bianca'

    # 1. Check if the input CSV from the previous step exists
    if not os.path.exists(input_csv_path):
        print(f"Error: Input file '{input_csv_path}' not found.")
        print("Please run the 'error_code_parser_v1' script first to generate it.")
        return

    # 2. Find all 'yyyy-mm-dd' directories in the current execution folder
    local_date_dirs = [d for d in glob.glob('????-??-??') if os.path.isdir(d)]

    if not local_date_dirs:
        print("No 'yyyy-mm-dd' formatted subdirectories found in the current folder.")
        return
    
    print(f"Found local date folders to scan for: {local_date_dirs}")

    # 3. Create specific search patterns based on the folders found locally
    search_patterns = []
    for date_dir in local_date_dirs:
        pattern = os.path.join(log_search_root, date_dir, "??", "*.log")
        search_patterns.append(pattern)

    # 4. Find all available .log files in the target directories and map them
    available_logs = find_all_logs(search_patterns)
    
    if not available_logs:
        print(f"Warning: No .log files were found in any of the target search paths.")

    # 5. Read the input CSV and find matches
    results_to_write = []
    try:
        with open(input_csv_path, 'r', newline='', encoding='utf-8') as infile:
            reader = csv.DictReader(infile)
            for row in reader:
                original_txt_path = row.get('Filepath')
                if not original_txt_path:
                    continue

                # Get the base name of the .txt file, e.g., "file" from "path/to/file.txt"
                txt_base_name = os.path.splitext(os.path.basename(original_txt_path))[0]

                # Look for the corresponding .log file in our map
                found_log_path = available_logs.get(txt_base_name, "Not Found")
                
                if found_log_path != "Not Found":
                    print(f"Match found for '{txt_base_name}': {found_log_path}")
                else:
                    print(f"No match found for '{txt_base_name}'")
                
                results_to_write.append({
                    'Original_Txt_Filepath': original_txt_path,
                    'Corresponding_Log_Filepath': found_log_path
                })
        
        # 6. Write the results to the new CSV file
        if not results_to_write:
            print("No filepaths were processed from the input CSV.")
            return

        with open(output_csv_path, 'w', newline='', encoding='utf-8') as outfile:
            header = ['Original_Txt_Filepath', 'Corresponding_Log_Filepath']
            writer = csv.DictWriter(outfile, fieldnames=header)
            writer.writeheader()
            writer.writerows(results_to_write)

        print(f"\nSearch complete. Results written to '{output_csv_path}'.")

    except Exception as e:
        print(f"An unexpected error occurred: {e}")

if __name__ == "__main__":
    main()
    